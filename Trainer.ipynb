{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBrwNYMP0cWO",
        "colab_type": "code",
        "outputId": "63d61127-6708-477c-f311-6e094c75ddbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd \"drive/My Drive/VQA-master\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/VQA-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaLLVY4u1t5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# from models.Simple_CNN_LSTM_Model import SimpleCNNLSTM, SimpleLSTM\n",
        "import models.Simple_CNN_LSTM_Model as models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1PHaehF3B3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_image_features=True\n",
        "batch_size = 1000\n",
        "print_every = 10\n",
        "options = {1: \"image, question\", 2: \"image features, question\", 3: \"concatenated image features, question embeddings\"}\n",
        "model_input = options[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUEHiTQc372N",
        "colab_type": "text"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjb84H5dgap7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_answers = np.load(\"train_answers.npy\")\n",
        "tensor_train_answers = torch.Tensor(train_answers).flatten()\n",
        "tensor_train_answers = tensor_train_answers.type(torch.long)\n",
        "\n",
        "val_answers = np.load(\"val_answers.npy\")\n",
        "tensor_val_answers = torch.Tensor(val_answers).flatten()\n",
        "tensor_val_answers = tensor_val_answers.type(torch.long)\n",
        "\n",
        "\n",
        "if model_input == \"image, question\":\n",
        "  train_images = np.load(\"train_image_list.npy\")\n",
        "  train_questions = np.load(\"train_questions.npy\")\n",
        "\n",
        "  val_images = np.load(\"val_image_list.npy\")\n",
        "  val_questions = np.load(\"val_questions.npy\")\n",
        "\n",
        "  tensor_train_images = torch.Tensor(train_images)\n",
        "  tensor_train_questions = torch.Tensor(train_questions)\n",
        "\n",
        "  tensor_val_images = torch.Tensor(val_images)\n",
        "  tensor_val_questions = torch.Tensor(val_questions)\n",
        "\n",
        "  trainset = data.TensorDataset(tensor_train_images,tensor_train_questions,tensor_train_answers)\n",
        "  valset = data.TensorDataset(tensor_val_images,tensor_val_questions,tensor_val_answers)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "elif model_input == \"image features, question\":\n",
        "  train_images = np.load(\"train_image_features.npy\")\n",
        "  train_questions = np.load(\"train_questions.npy\")\n",
        "\n",
        "  val_images = np.load(\"val_image_features.npy\")\n",
        "  val_questions = np.load(\"val_questions.npy\")\n",
        "\n",
        "  tensor_train_images = torch.Tensor(train_images)\n",
        "  tensor_train_questions = torch.Tensor(train_questions)\n",
        "\n",
        "  tensor_val_images = torch.Tensor(val_images)\n",
        "  tensor_val_questions = torch.Tensor(val_questions)\n",
        "\n",
        "  trainset = data.TensorDataset(tensor_train_images,tensor_train_questions,tensor_train_answers)\n",
        "  valset = data.TensorDataset(tensor_val_images,tensor_val_questions,tensor_val_answers)\n",
        "\n",
        "  num_workers = 2\n",
        "\n",
        "elif model_input == \"concatenated image features, question embeddings\":\n",
        "  train_input = np.load(\"combined_train_input.npy\")\n",
        "  val_input = np.load(\"combined_val_input.npy\")\n",
        "\n",
        "  tensor_train_input = torch.Tensor(train_input)\n",
        "  tensor_val_input = torch.Tensor(val_input)\n",
        "\n",
        "  trainset = data.TensorDataset(tensor_train_input, tensor_train_answers)\n",
        "  valset = data.TensorDataset(tensor_val_input, tensor_val_answers)\n",
        "  \n",
        "  num_workers = 2\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M57Wbz-44HBd",
        "colab_type": "text"
      },
      "source": [
        "#### Choose model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ynecbLrqOxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_matrix = np.load(\"weights_matrix.npy\")\n",
        "weights_matrix = torch.tensor(weights_matrix)\n",
        "model = models.SimpleCNNLSTM(weights_matrix, 2048, 1, model_input=model_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dS4E_c-4dp_",
        "colab_type": "text"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT_czxJkrlwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpufSQPT4FMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(predictions, labels):\n",
        "  predictions = torch.max(predictions, axis=1)[1]\n",
        "  ab = torch.abs(predictions-labels)\n",
        "  ab = ab.detach().numpy()\n",
        "  mn = np.minimum(ab, 1)\n",
        "  eq = 1-mn\n",
        "  correct = np.sum(eq)\n",
        "  total = eq.shape[0]\n",
        "  return correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcEf05wAmYap",
        "colab_type": "code",
        "outputId": "cca0f804-5fbe-4cf0-917f-e1317ed89a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(500):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        if i % print_every == 0 and i>0:\n",
        "          print(\"Train batch \",i+1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if model_input == \"image, question\":\n",
        "          images, questions, labels = data\n",
        "          images = images.type(torch.float32)\n",
        "          labels = labels.flatten().type(torch.long)\n",
        "          labels = labels.view(-1)\n",
        "\n",
        "          outputs = model(images, questions)\n",
        "\n",
        "\n",
        "        elif model_input == \"image features, question\":\n",
        "          image_features, questions, labels = data\n",
        "          image_features = image_features.type(torch.float32)\n",
        "          labels = labels.flatten().type(torch.long)\n",
        "          labels = labels.view(-1)\n",
        "\n",
        "          outputs = model(image_features, questions)\n",
        "\n",
        "\n",
        "        elif model_input == \"concatenated image features, question embeddings\":\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.type(torch.float32)\n",
        "          labels = labels.flatten().type(torch.long)\n",
        "          labels = labels.view(-1)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "\n",
        "        batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        total_loss += running_loss\n",
        "        running_loss = 0.0\n",
        "\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(valloader, 0):\n",
        "          if i % print_every == 0 and i>0:\n",
        "            print(\"Val batch \",i+1)\n",
        "\n",
        "          if model_input == \"image, question\":\n",
        "            images, questions, labels = data\n",
        "            images = images.type(torch.float32)\n",
        "            labels = labels.flatten().type(torch.long)\n",
        "            labels = labels.view(-1)\n",
        "\n",
        "            outputs = model(images, questions)\n",
        "\n",
        "\n",
        "          elif model_input == \"image features, question\":\n",
        "            image_features, questions, labels = data\n",
        "            image_features = image_features.type(torch.float32)\n",
        "            labels = labels.flatten().type(torch.long)\n",
        "            labels = labels.view(-1)\n",
        "\n",
        "            outputs = model(image_features, questions)\n",
        "\n",
        "\n",
        "          elif model_input == \"concatenated image features, question embeddings\":\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.type(torch.float32)\n",
        "            labels = labels.flatten().type(torch.long)\n",
        "            labels = labels.view(-1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "          batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "          val_correct += batch_correct\n",
        "          val_total += batch_total\n",
        "          \n",
        "    print(\"Epoch: \",epoch+1,\" Loss: \",total_loss,\" Train-Accuracy: \", correct/total,\" Val-Accuracy: \",val_correct/val_total)\n",
        "    \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1  Loss:  33.939743995666504  Train-Accuracy:  0.12251112672757086  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  2  Loss:  33.367817878723145  Train-Accuracy:  0.23143593347388147  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  3  Loss:  33.35927391052246  Train-Accuracy:  0.23518388381353947  Val-Accuracy:  0.21863799283154123\n",
            "Epoch:  4  Loss:  33.361892223358154  Train-Accuracy:  0.2344811431248536  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  5  Loss:  33.363544940948486  Train-Accuracy:  0.24267978449285546  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  6  Loss:  33.28286170959473  Train-Accuracy:  0.24877020379479972  Val-Accuracy:  0.2270011947431302\n",
            "Epoch:  7  Loss:  33.25136613845825  Train-Accuracy:  0.258608573436402  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  8  Loss:  33.256996631622314  Train-Accuracy:  0.2595455610213165  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  9  Loss:  33.21515893936157  Train-Accuracy:  0.27453736237994847  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  10  Loss:  33.162710666656494  Train-Accuracy:  0.277348325134692  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  11  Loss:  33.186079025268555  Train-Accuracy:  0.2808620285781213  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  12  Loss:  33.19979667663574  Train-Accuracy:  0.2787538065120637  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  13  Loss:  33.14493989944458  Train-Accuracy:  0.2871866947762942  Val-Accuracy:  0.24850657108721624\n",
            "Epoch:  14  Loss:  33.14425992965698  Train-Accuracy:  0.2928086202857812  Val-Accuracy:  0.2532855436081243\n",
            "Epoch:  15  Loss:  33.09898328781128  Train-Accuracy:  0.294214101663153  Val-Accuracy:  0.24850657108721624\n",
            "Epoch:  16  Loss:  33.074891567230225  Train-Accuracy:  0.29983602717263996  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  17  Loss:  33.089789390563965  Train-Accuracy:  0.303583977512298  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  18  Loss:  33.11626577377319  Train-Accuracy:  0.30334973061606935  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  19  Loss:  33.09428548812866  Train-Accuracy:  0.3047552119934411  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  20  Loss:  33.13727045059204  Train-Accuracy:  0.2841414851253221  Val-Accuracy:  0.24970131421744324\n",
            "Epoch:  21  Loss:  33.07011699676514  Train-Accuracy:  0.30780042164441324  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  22  Loss:  33.05491542816162  Train-Accuracy:  0.3103771375029281  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  23  Loss:  33.044453144073486  Train-Accuracy:  0.3066291871632701  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  24  Loss:  33.06435298919678  Train-Accuracy:  0.30334973061606935  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  25  Loss:  33.09721374511719  Train-Accuracy:  0.3021784961349262  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  26  Loss:  33.09327268600464  Train-Accuracy:  0.2974935582103537  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  27  Loss:  33.061827182769775  Train-Accuracy:  0.29608807683298194  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  28  Loss:  33.038146018981934  Train-Accuracy:  0.31271960646521435  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  29  Loss:  33.05308198928833  Train-Accuracy:  0.3124853595689857  Val-Accuracy:  0.24970131421744324\n",
            "Epoch:  30  Loss:  33.06339883804321  Train-Accuracy:  0.31271960646521435  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  31  Loss:  33.01886463165283  Train-Accuracy:  0.3171702974935582  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  32  Loss:  33.01890754699707  Train-Accuracy:  0.3188100257671586  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  33  Loss:  33.00985908508301  Train-Accuracy:  0.32326071679550245  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  34  Loss:  32.9942307472229  Train-Accuracy:  0.3239634574841883  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  35  Loss:  33.00074243545532  Train-Accuracy:  0.3227922230030452  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  36  Loss:  33.03107833862305  Train-Accuracy:  0.32021550714453034  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  37  Loss:  32.99514198303223  Train-Accuracy:  0.32138674162567343  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  38  Loss:  33.02324438095093  Train-Accuracy:  0.31623330990864373  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  39  Loss:  32.98264026641846  Train-Accuracy:  0.32326071679550245  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  40  Loss:  32.95497465133667  Train-Accuracy:  0.3265401733427032  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  41  Loss:  32.998671531677246  Train-Accuracy:  0.3216209885219021  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  42  Loss:  32.99178075790405  Train-Accuracy:  0.3272429140313891  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  43  Loss:  32.96050024032593  Train-Accuracy:  0.3309908643710471  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  44  Loss:  32.977632999420166  Train-Accuracy:  0.32513469196533146  Val-Accuracy:  0.24731182795698925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0d168d13991e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m           \u001b[0mbatch_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m           \u001b[0mval_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mval_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-04f1472b607d>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(predictions, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCd9IxVU3yD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}