{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple CNN+LSTM Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTmG1s8L9we",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "79f9b68c-5435-4f5a-869d-e49476dc1d63"
      },
      "source": [
        "%cd \"drive/My Drive/VQA-master\""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/VQA-master'\n",
            "/content/drive/My Drive/VQA-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz4O7JHkF-Xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json \n",
        "  \n",
        "# JSON file\n",
        "def read_json(filename): \n",
        "  f = open (filename, \"r\") \n",
        "    \n",
        "  # Reading from file \n",
        "  data = json.loads(f.read()) \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynmZXNwzF_Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = read_json(\"train_dataset_5k_tokenised.json\")\n",
        "val_data = read_json(\"val_dataset_1k_tokenised.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qkuaXCqPuLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMXJm9B4P3NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9BVTM74Tkdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "15bfb177-dad1-4cb3-f993-827638263588"
      },
      "source": [
        "!pip install bcolz"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.2)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp36-cp36m-linux_x86_64.whl size=2662291 sha256=56c7035b501b7512f1b4f09f9628ebcd6e269c92aaf872dd5df1a35afc0eb037\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjibYVw2R24K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bcolz\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "glove_path = \"\"\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'6B.50.dat', mode='w')\n",
        "\n",
        "with open(f'glove.6B.50d.txt', 'rb') as f:\n",
        "    for l in f:\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vect = np.array(line[1:]).astype(np.float)\n",
        "        vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 50)), rootdir=f'6B.50.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'6B.50_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'6B.50_idx.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpQCqBu2TjUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = bcolz.open(f'6B.50.dat')[:]\n",
        "words = pickle.load(open(f'6B.50_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'6B.50_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBrTNg-_c4AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRCCTMrp0NpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_len = 400001\n",
        "weights_matrix = np.zeros((matrix_len, 50))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(glove.keys()):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu05PnLw_Vcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.size()\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim\n",
        "\n",
        "class ToyNN(nn.Module):\n",
        "    def __init__(self, weights_matrix, hidden_size, num_layers):\n",
        "        super(ToyNN, self).__init__()\n",
        "        print(weights_matrix.size())\n",
        "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
        "        \n",
        "    def forward(self, inp, hidden):\n",
        "        return self.gru(self.embedding(inp))\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        return Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x3sNvx1H1Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_features = np.load(\"train_image_features.npy\")\n",
        "# questions = np.load(\"train_questions.npy\")\n",
        "# answers = np.load(\"train_answers.npy\")\n",
        "# combined_train_input = np.load(\"combined_input.npy\")\n",
        "\n",
        "image_features = np.load(\"val_image_features.npy\")\n",
        "questions = np.load(\"val_questions.npy\")\n",
        "val_answers = np.load(\"val_answers.npy\")\n",
        "# combined_val_input = np.load(\"combined_val_input.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw6QXwIWGw_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c09d0ab-fed3-4a23-a9c6-0699322a180d"
      },
      "source": [
        "import torch\n",
        "weights_matrix = torch.tensor(weights_matrix)\n",
        "lstm = ToyNN(weights_matrix, 2048, 1)\n",
        "questions = torch.tensor(questions, dtype=torch.long)\n",
        "# image_features = torch.tensor(image_features, dtype=torch.float)\n",
        "# image_features = image_features.view(1, image_features.size(0), image_features.size(1))\n",
        "output = lstm(questions, image_features)\n",
        "# print(output.size())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([400001, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ChmJOfG_1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c9e776e8-ce77-4499-9075-bdc9a0157b13"
      },
      "source": [
        "a,b = output\n",
        "b = b.view(b.size(1), b.size(2))\n",
        "image_features = torch.tensor(image_features, dtype=torch.float)\n",
        "print(image_features.size())\n",
        "print(b.size())"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([837, 512])\n",
            "torch.Size([837, 2048])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNlZTIHaHHwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74846db5-eaf3-4788-ddf9-5097b833fad7"
      },
      "source": [
        "combined_input = torch.cat((image_features,b), 1)\n",
        "print(combined_input.size())"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([837, 2560])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqsK2jL7IndS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_val_input = combined_input.detach().numpy()\n",
        "np.save(\"combined_val_input.npy\", combined_val_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijGShvbeq9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ1_ZiEnLZZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_features = np.load(\"train_image_features.npy\")\n",
        "# questions = np.load(\"train_questions.npy\")\n",
        "train_answers = np.load(\"train_answers.npy\")\n",
        "combined_train_input = np.load(\"combined_train_input.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHEd-8N1IIoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_features = np.load(\"val_image_features.npy\")\n",
        "# questions = np.load(\"val_questions.npy\")\n",
        "val_answers = np.load(\"val_answers.npy\")\n",
        "combined_val_input = np.load(\"combined_val_input.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SV5_SqRyW67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2560, 1000)\n",
        "        # self.fc2 = nn.Linear(2000, 1500)\n",
        "        # self.fc3 = nn.Linear(1500, 1000)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.relu(self.fc2(x))\n",
        "        # x = F.relu(self.fc3(x))\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEeUI9zfy6zh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e5197b31-c8c3-4231-b635-ecc577ed00d0"
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "tensor_x = torch.Tensor(combined_train_input)\n",
        "tensor_y = torch.Tensor(train_answers).flatten()\n",
        "tensor_y = tensor_y.type(torch.long)\n",
        "print(tensor_x.size())\n",
        "print(tensor_y.size())\n",
        "print(tensor_x.dtype)\n",
        "print(tensor_y.dtype)\n",
        "trainset = data.TensorDataset(tensor_x,tensor_y)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=2)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4269, 2560])\n",
            "torch.Size([4269])\n",
            "torch.float32\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2s2kQlRJjSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "322f1a43-266e-4f4e-f8ec-c434f55ed639"
      },
      "source": [
        "from torch.utils import data\n",
        "tensor_x = torch.Tensor(combined_val_input)\n",
        "tensor_y = torch.Tensor(val_answers).flatten()\n",
        "tensor_y = tensor_y.type(torch.long)\n",
        "print(tensor_x.size())\n",
        "print(tensor_y.size())\n",
        "print(tensor_x.dtype)\n",
        "print(tensor_y.dtype)\n",
        "valset = data.TensorDataset(tensor_x,tensor_y)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=1000, shuffle=True, num_workers=2)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([837, 2560])\n",
            "torch.Size([837])\n",
            "torch.float32\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udzW3BfG0C0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7tFSKAV1m1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(predictions, labels):\n",
        "  predictions = torch.max(predictions, axis=1)[1]\n",
        "  # print(predictions)\n",
        "  # print(labels)\n",
        "  # print(predictions.size())\n",
        "  # print(labels.size())\n",
        "  ab = torch.abs(predictions-labels)\n",
        "  # print(ab.size())\n",
        "  ab = ab.detach().numpy()\n",
        "  mn = np.minimum(ab, 1)\n",
        "  eq = 1-mn\n",
        "  # eq = 1 - torch.min(torch.abs(predictions-labels), 1)\n",
        "  correct = np.sum(eq)\n",
        "  # print(correct)\n",
        "  total = eq.shape[0]\n",
        "  return correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMcbdkt2zzZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "198cb41e-4698-4b38-da3b-9806873bf8ee"
      },
      "source": [
        "for epoch in range(500):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    net.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 1 == 0:    # print every 2000 mini-batches\n",
        "        #     print('[%d, %5d] loss: %.3f' %\n",
        "        #           (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "        total_loss += running_loss\n",
        "        running_loss = 0.0\n",
        "\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(valloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "          batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "          val_correct += batch_correct\n",
        "          val_total += batch_total\n",
        "          \n",
        "    print(\"Epoch: \",epoch,\" Loss: \",total_loss,\" Train-Accuracy: \", correct/total,\" Val-Accuracy: \",val_correct/val_total)\n",
        "    \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  Loss:  34.53112554550171  Train-Accuracy:  0.015928788943546497  Val-Accuracy:  0.03464755077658303\n",
            "Epoch:  1  Loss:  34.46015644073486  Train-Accuracy:  0.06371515577418599  Val-Accuracy:  0.11947431302270012\n",
            "Epoch:  2  Loss:  34.114097595214844  Train-Accuracy:  0.2101194659170766  Val-Accuracy:  0.2078853046594982\n",
            "Epoch:  3  Loss:  33.54840564727783  Train-Accuracy:  0.23518388381353947  Val-Accuracy:  0.23178016726403824\n",
            "Epoch:  4  Loss:  33.43857955932617  Train-Accuracy:  0.23284141485125323  Val-Accuracy:  0.23536439665471923\n",
            "Epoch:  5  Loss:  33.388670444488525  Train-Accuracy:  0.23213867416256734  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  6  Loss:  33.37896728515625  Train-Accuracy:  0.23167018037011008  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  7  Loss:  33.38943529129028  Train-Accuracy:  0.23167018037011008  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  8  Loss:  33.36867618560791  Train-Accuracy:  0.23167018037011008  Val-Accuracy:  0.23297491039426524\n",
            "Epoch:  9  Loss:  33.37070274353027  Train-Accuracy:  0.2337784024361677  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  10  Loss:  33.35631990432739  Train-Accuracy:  0.24361677207776997  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  11  Loss:  33.3388614654541  Train-Accuracy:  0.2501756851721715  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  12  Loss:  33.354952812194824  Train-Accuracy:  0.2607167955024596  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  13  Loss:  33.32424306869507  Train-Accuracy:  0.2590770672288592  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  14  Loss:  33.330541133880615  Train-Accuracy:  0.2560318575778871  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  15  Loss:  33.31083679199219  Train-Accuracy:  0.26961817755914735  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  16  Loss:  33.290677547454834  Train-Accuracy:  0.2747716092761771  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  17  Loss:  33.29628276824951  Train-Accuracy:  0.27453736237994847  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  18  Loss:  33.286561012268066  Train-Accuracy:  0.275474349964863  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  19  Loss:  33.28840780258179  Train-Accuracy:  0.27453736237994847  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  20  Loss:  33.304723262786865  Train-Accuracy:  0.27524010306863433  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  21  Loss:  33.230897426605225  Train-Accuracy:  0.27430311548371983  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  22  Loss:  33.26946783065796  Train-Accuracy:  0.28062778168189273  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  23  Loss:  33.23604679107666  Train-Accuracy:  0.2803935347856641  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  24  Loss:  33.23938703536987  Train-Accuracy:  0.2747716092761771  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  25  Loss:  33.24394416809082  Train-Accuracy:  0.28203326305926446  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  26  Loss:  33.24679660797119  Train-Accuracy:  0.2803935347856641  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  27  Loss:  33.2351279258728  Train-Accuracy:  0.2813305223705786  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  28  Loss:  33.24784803390503  Train-Accuracy:  0.27898805340829236  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  29  Loss:  33.24622964859009  Train-Accuracy:  0.2813305223705786  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  30  Loss:  33.22045183181763  Train-Accuracy:  0.2827360037479503  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  31  Loss:  33.2352032661438  Train-Accuracy:  0.2834387444366362  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  32  Loss:  33.22008419036865  Train-Accuracy:  0.28250175685172174  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  33  Loss:  33.2061562538147  Train-Accuracy:  0.2897634106348091  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  34  Loss:  33.20214223861694  Train-Accuracy:  0.2857812133989225  Val-Accuracy:  0.25089605734767023\n",
            "Epoch:  35  Loss:  33.197439670562744  Train-Accuracy:  0.284844225814008  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  36  Loss:  33.23107576370239  Train-Accuracy:  0.2853127196064652  Val-Accuracy:  0.2520908004778972\n",
            "Epoch:  37  Loss:  33.202470779418945  Train-Accuracy:  0.28835792925743736  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  38  Loss:  33.19608688354492  Train-Accuracy:  0.28507847271023656  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  39  Loss:  33.18579626083374  Train-Accuracy:  0.28952916373858045  Val-Accuracy:  0.25089605734767023\n",
            "Epoch:  40  Loss:  33.22190284729004  Train-Accuracy:  0.28835792925743736  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  41  Loss:  33.19487285614014  Train-Accuracy:  0.29140313890840946  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  42  Loss:  33.23904848098755  Train-Accuracy:  0.28742094167252286  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  43  Loss:  33.19115352630615  Train-Accuracy:  0.28999765753103773  Val-Accuracy:  0.2520908004778972\n",
            "Epoch:  44  Loss:  33.16750526428223  Train-Accuracy:  0.286718200983837  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  45  Loss:  33.18285846710205  Train-Accuracy:  0.29304286718200984  Val-Accuracy:  0.23536439665471923\n",
            "Epoch:  46  Loss:  33.155755043029785  Train-Accuracy:  0.2937456078706957  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  47  Loss:  33.18663549423218  Train-Accuracy:  0.2916373858046381  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  48  Loss:  33.14396953582764  Train-Accuracy:  0.294214101663153  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  49  Loss:  33.16395092010498  Train-Accuracy:  0.2897634106348091  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  50  Loss:  33.17843246459961  Train-Accuracy:  0.2925743733895526  Val-Accuracy:  0.24850657108721624\n",
            "Epoch:  51  Loss:  33.18692207336426  Train-Accuracy:  0.2916373858046381  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  52  Loss:  33.17781925201416  Train-Accuracy:  0.29679081752166786  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  53  Loss:  33.1464581489563  Train-Accuracy:  0.29679081752166786  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  54  Loss:  33.15449571609497  Train-Accuracy:  0.2951510892480675  Val-Accuracy:  0.24731182795698925\n",
            "Epoch:  55  Loss:  33.18146896362305  Train-Accuracy:  0.2951510892480675  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  56  Loss:  33.137038230895996  Train-Accuracy:  0.2981962988990396  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  57  Loss:  33.16464042663574  Train-Accuracy:  0.3000702740688686  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  58  Loss:  33.165008544921875  Train-Accuracy:  0.2981962988990396  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  59  Loss:  33.147096157073975  Train-Accuracy:  0.2972593113141251  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  60  Loss:  33.14500856399536  Train-Accuracy:  0.30334973061606935  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  61  Loss:  33.12951469421387  Train-Accuracy:  0.3000702740688686  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  62  Loss:  33.14519929885864  Train-Accuracy:  0.30241274303115484  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  63  Loss:  33.148518085479736  Train-Accuracy:  0.2951510892480675  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  64  Loss:  33.15900230407715  Train-Accuracy:  0.30194424923869756  Val-Accuracy:  0.23655913978494625\n",
            "Epoch:  65  Loss:  33.16234350204468  Train-Accuracy:  0.3012415085500117  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  66  Loss:  33.15464496612549  Train-Accuracy:  0.3026469899273835  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  67  Loss:  33.146835803985596  Train-Accuracy:  0.3010072616537831  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  68  Loss:  33.16374397277832  Train-Accuracy:  0.3049894588896697  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  69  Loss:  33.169318199157715  Train-Accuracy:  0.2977278051065823  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  70  Loss:  33.13902473449707  Train-Accuracy:  0.30522370578589836  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  71  Loss:  33.12724828720093  Train-Accuracy:  0.3059264464745842  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  72  Loss:  33.16021013259888  Train-Accuracy:  0.3066291871632701  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  73  Loss:  33.15148401260376  Train-Accuracy:  0.30522370578589836  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  74  Loss:  33.13383436203003  Train-Accuracy:  0.30826891543687046  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  75  Loss:  33.12353754043579  Train-Accuracy:  0.3080346685406418  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  76  Loss:  33.129172801971436  Train-Accuracy:  0.30545795268212694  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  77  Loss:  33.1154351234436  Train-Accuracy:  0.30780042164441324  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  78  Loss:  33.12201547622681  Train-Accuracy:  0.30452096509721244  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  79  Loss:  33.135769844055176  Train-Accuracy:  0.30826891543687046  Val-Accuracy:  0.24611708482676226\n",
            "Epoch:  80  Loss:  33.121212005615234  Train-Accuracy:  0.29491684235183885  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  81  Loss:  33.117337226867676  Train-Accuracy:  0.3103771375029281  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  82  Loss:  33.13727951049805  Train-Accuracy:  0.30452096509721244  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  83  Loss:  33.08201503753662  Train-Accuracy:  0.3087374092293277  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  84  Loss:  33.10515546798706  Train-Accuracy:  0.30733192785195595  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  85  Loss:  33.10151815414429  Train-Accuracy:  0.3103771375029281  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  86  Loss:  33.073654651641846  Train-Accuracy:  0.3106113843991567  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  87  Loss:  33.08022403717041  Train-Accuracy:  0.3103771375029281  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  88  Loss:  33.12699270248413  Train-Accuracy:  0.3096743968142422  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  89  Loss:  33.07027006149292  Train-Accuracy:  0.3120168657765285  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  90  Loss:  33.06247091293335  Train-Accuracy:  0.3120168657765285  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  91  Loss:  33.10579442977905  Train-Accuracy:  0.31084563129538534  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  92  Loss:  33.12421131134033  Train-Accuracy:  0.31225111267275707  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  93  Loss:  33.07392072677612  Train-Accuracy:  0.31084563129538534  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  94  Loss:  33.10722780227661  Train-Accuracy:  0.3131881002576716  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  95  Loss:  33.05915355682373  Train-Accuracy:  0.31225111267275707  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  96  Loss:  33.08647871017456  Train-Accuracy:  0.3141250878425861  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  97  Loss:  33.076271057128906  Train-Accuracy:  0.31365659405012886  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  98  Loss:  33.10407066345215  Train-Accuracy:  0.3150620754275006  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  99  Loss:  33.0844841003418  Train-Accuracy:  0.31459358163504336  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  100  Loss:  33.077866554260254  Train-Accuracy:  0.31459358163504336  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  101  Loss:  33.0917763710022  Train-Accuracy:  0.3131881002576716  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  102  Loss:  33.10713338851929  Train-Accuracy:  0.31670180370110096  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  103  Loss:  33.11930990219116  Train-Accuracy:  0.31623330990864373  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  104  Loss:  33.045273780822754  Train-Accuracy:  0.3159990630124151  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  105  Loss:  33.071128368377686  Train-Accuracy:  0.31529632232372923  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  106  Loss:  33.079811573028564  Train-Accuracy:  0.31623330990864373  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  107  Loss:  33.071481704711914  Train-Accuracy:  0.3169360505973296  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  108  Loss:  33.07933855056763  Train-Accuracy:  0.3159990630124151  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  109  Loss:  33.07086801528931  Train-Accuracy:  0.31623330990864373  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  110  Loss:  33.07910346984863  Train-Accuracy:  0.31857577887092997  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  111  Loss:  33.11654043197632  Train-Accuracy:  0.3169360505973296  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  112  Loss:  33.06036043167114  Train-Accuracy:  0.3174045443897868  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  113  Loss:  33.100727558135986  Train-Accuracy:  0.3178730381822441  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  114  Loss:  33.05580806732178  Train-Accuracy:  0.3174045443897868  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  115  Loss:  33.058287620544434  Train-Accuracy:  0.3195127664558445  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  116  Loss:  33.07273244857788  Train-Accuracy:  0.31834153197470133  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  117  Loss:  33.08125305175781  Train-Accuracy:  0.3199812602483017  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  118  Loss:  33.078227519989014  Train-Accuracy:  0.32021550714453034  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  119  Loss:  33.073522090911865  Train-Accuracy:  0.3171702974935582  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  120  Loss:  33.07863664627075  Train-Accuracy:  0.31670180370110096  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  121  Loss:  33.05140161514282  Train-Accuracy:  0.32068400093698757  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  122  Loss:  33.07041692733765  Train-Accuracy:  0.31623330990864373  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  123  Loss:  33.08651113510132  Train-Accuracy:  0.31857577887092997  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  124  Loss:  33.02668762207031  Train-Accuracy:  0.3178730381822441  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  125  Loss:  33.07230186462402  Train-Accuracy:  0.31974701335207306  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  126  Loss:  33.09454965591431  Train-Accuracy:  0.31927851955961584  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  127  Loss:  33.05632781982422  Train-Accuracy:  0.3195127664558445  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  128  Loss:  33.054190158843994  Train-Accuracy:  0.3188100257671586  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  129  Loss:  33.06825017929077  Train-Accuracy:  0.320449754040759  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  130  Loss:  33.04318141937256  Train-Accuracy:  0.320449754040759  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  131  Loss:  33.04906940460205  Train-Accuracy:  0.31974701335207306  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  132  Loss:  33.046701431274414  Train-Accuracy:  0.3225579761068166  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  133  Loss:  33.10283279418945  Train-Accuracy:  0.3178730381822441  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  134  Loss:  33.03124713897705  Train-Accuracy:  0.32208948231435935  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  135  Loss:  33.082125186920166  Train-Accuracy:  0.32302646989927386  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  136  Loss:  33.09980535507202  Train-Accuracy:  0.320449754040759  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  137  Loss:  33.06915473937988  Train-Accuracy:  0.3225579761068166  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  138  Loss:  33.047340393066406  Train-Accuracy:  0.3225579761068166  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  139  Loss:  33.0240273475647  Train-Accuracy:  0.3216209885219021  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  140  Loss:  33.02929353713989  Train-Accuracy:  0.3216209885219021  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  141  Loss:  33.06633520126343  Train-Accuracy:  0.32208948231435935  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  142  Loss:  33.0514349937439  Train-Accuracy:  0.3239634574841883  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  143  Loss:  33.05103826522827  Train-Accuracy:  0.3227922230030452  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  144  Loss:  33.02354574203491  Train-Accuracy:  0.3239634574841883  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  145  Loss:  33.056196212768555  Train-Accuracy:  0.3237292105879597  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  146  Loss:  33.063538551330566  Train-Accuracy:  0.3244319512766456  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  147  Loss:  33.0525918006897  Train-Accuracy:  0.3244319512766456  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  148  Loss:  33.04532289505005  Train-Accuracy:  0.3239634574841883  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  149  Loss:  33.02142858505249  Train-Accuracy:  0.3249004450691028  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  150  Loss:  33.01813983917236  Train-Accuracy:  0.3249004450691028  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  151  Loss:  33.04952669143677  Train-Accuracy:  0.32607167955024596  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  152  Loss:  33.01906681060791  Train-Accuracy:  0.32607167955024596  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  153  Loss:  33.04741048812866  Train-Accuracy:  0.3253689388615601  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  154  Loss:  33.009395122528076  Train-Accuracy:  0.3265401733427032  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  155  Loss:  33.03962755203247  Train-Accuracy:  0.3256031857577887  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  156  Loss:  33.04680109024048  Train-Accuracy:  0.32700866713516047  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  157  Loss:  33.013694286346436  Train-Accuracy:  0.3263059264464746  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  158  Loss:  33.06888151168823  Train-Accuracy:  0.3272429140313891  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  159  Loss:  33.01000213623047  Train-Accuracy:  0.32677442023893183  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  160  Loss:  33.02411079406738  Train-Accuracy:  0.3258374326540173  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  161  Loss:  33.01241493225098  Train-Accuracy:  0.3263059264464746  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  162  Loss:  33.05954837799072  Train-Accuracy:  0.327945654720075  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  163  Loss:  33.02531671524048  Train-Accuracy:  0.32771140782384633  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  164  Loss:  32.986473083496094  Train-Accuracy:  0.32700866713516047  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  165  Loss:  33.02976989746094  Train-Accuracy:  0.32771140782384633  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  166  Loss:  33.011476039886475  Train-Accuracy:  0.32911688920121807  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  167  Loss:  33.03432655334473  Train-Accuracy:  0.32911688920121807  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  168  Loss:  33.01307153701782  Train-Accuracy:  0.3288826423049895  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  169  Loss:  33.04009819030762  Train-Accuracy:  0.3288826423049895  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  170  Loss:  33.02432584762573  Train-Accuracy:  0.32864839540876084  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  171  Loss:  33.0108323097229  Train-Accuracy:  0.32864839540876084  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  172  Loss:  33.01847314834595  Train-Accuracy:  0.32958538299367535  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  173  Loss:  33.016963481903076  Train-Accuracy:  0.3249004450691028  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  174  Loss:  33.01602363586426  Train-Accuracy:  0.3263059264464746  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  175  Loss:  33.01062822341919  Train-Accuracy:  0.3256031857577887  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  176  Loss:  33.018632888793945  Train-Accuracy:  0.3293511360974467  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  177  Loss:  33.04374551773071  Train-Accuracy:  0.3293511360974467  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  178  Loss:  32.995323181152344  Train-Accuracy:  0.33005387678613257  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  179  Loss:  32.98638296127319  Train-Accuracy:  0.3302881236823612  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  180  Loss:  33.00506591796875  Train-Accuracy:  0.3302881236823612  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  181  Loss:  33.007747650146484  Train-Accuracy:  0.3319278519559616  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  182  Loss:  33.04866552352905  Train-Accuracy:  0.3323963457484188  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  183  Loss:  32.990830421447754  Train-Accuracy:  0.3321620988521902  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  184  Loss:  33.01785182952881  Train-Accuracy:  0.3293511360974467  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  185  Loss:  33.02086114883423  Train-Accuracy:  0.33169360505973294  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  186  Loss:  32.99226999282837  Train-Accuracy:  0.32958538299367535  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  187  Loss:  33.01753520965576  Train-Accuracy:  0.32981962988990393  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  188  Loss:  33.01011085510254  Train-Accuracy:  0.3288826423049895  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  189  Loss:  33.017595291137695  Train-Accuracy:  0.3309908643710471  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  190  Loss:  33.00168228149414  Train-Accuracy:  0.32911688920121807  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  191  Loss:  33.02210092544556  Train-Accuracy:  0.3309908643710471  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  192  Loss:  32.989192485809326  Train-Accuracy:  0.3309908643710471  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  193  Loss:  33.00859308242798  Train-Accuracy:  0.3333333333333333  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  194  Loss:  33.02512454986572  Train-Accuracy:  0.3328648395408761  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  195  Loss:  32.98286485671997  Train-Accuracy:  0.3321620988521902  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  196  Loss:  33.001612186431885  Train-Accuracy:  0.32864839540876084  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  197  Loss:  32.99842309951782  Train-Accuracy:  0.3328648395408761  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  198  Loss:  32.97960567474365  Train-Accuracy:  0.33309908643710473  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  199  Loss:  33.01181077957153  Train-Accuracy:  0.3319278519559616  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  200  Loss:  32.99440908432007  Train-Accuracy:  0.33309908643710473  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  201  Loss:  32.986196517944336  Train-Accuracy:  0.33356758022956196  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  202  Loss:  33.02889633178711  Train-Accuracy:  0.3342703209182478  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  203  Loss:  32.98262405395508  Train-Accuracy:  0.3356758022956196  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  204  Loss:  32.99326515197754  Train-Accuracy:  0.3319278519559616  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  205  Loss:  32.997336864471436  Train-Accuracy:  0.3338018271257906  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  206  Loss:  33.00894784927368  Train-Accuracy:  0.3349730616069337  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  207  Loss:  32.98649978637695  Train-Accuracy:  0.3347388147107051  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  208  Loss:  32.980353355407715  Train-Accuracy:  0.3352073085031623  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  209  Loss:  33.02278470993042  Train-Accuracy:  0.33614429608807683  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  210  Loss:  32.996315002441406  Train-Accuracy:  0.3356758022956196  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  211  Loss:  32.98385715484619  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  212  Loss:  33.01547908782959  Train-Accuracy:  0.33614429608807683  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  213  Loss:  32.96190309524536  Train-Accuracy:  0.33731553056922  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  214  Loss:  32.9865345954895  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  215  Loss:  32.954018115997314  Train-Accuracy:  0.3352073085031623  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  216  Loss:  32.96828842163086  Train-Accuracy:  0.3352073085031623  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  217  Loss:  32.984705448150635  Train-Accuracy:  0.33661278988053406  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  218  Loss:  32.972649574279785  Train-Accuracy:  0.3323963457484188  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  219  Loss:  32.9351167678833  Train-Accuracy:  0.3356758022956196  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  220  Loss:  33.00240230560303  Train-Accuracy:  0.33450456781447646  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  221  Loss:  32.98436784744263  Train-Accuracy:  0.3359100491918482  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  222  Loss:  32.969611167907715  Train-Accuracy:  0.3359100491918482  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  223  Loss:  33.01835489273071  Train-Accuracy:  0.33614429608807683  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  224  Loss:  32.999855518341064  Train-Accuracy:  0.33614429608807683  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  225  Loss:  32.982189655303955  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  226  Loss:  33.01829767227173  Train-Accuracy:  0.33661278988053406  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  227  Loss:  32.983691692352295  Train-Accuracy:  0.3356758022956196  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  228  Loss:  32.97289848327637  Train-Accuracy:  0.33754977746544856  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  229  Loss:  32.99392080307007  Train-Accuracy:  0.33754977746544856  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  230  Loss:  33.005913734436035  Train-Accuracy:  0.3368470367767627  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  231  Loss:  33.01327896118164  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  232  Loss:  33.005321979522705  Train-Accuracy:  0.33731553056922  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  233  Loss:  32.97081995010376  Train-Accuracy:  0.3368470367767627  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  234  Loss:  32.97208881378174  Train-Accuracy:  0.3352073085031623  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  235  Loss:  32.96008253097534  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  236  Loss:  32.994858741760254  Train-Accuracy:  0.33731553056922  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  237  Loss:  32.97692346572876  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  238  Loss:  32.96584463119507  Train-Accuracy:  0.33708128367299134  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  239  Loss:  32.9915885925293  Train-Accuracy:  0.33731553056922  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  240  Loss:  32.992305755615234  Train-Accuracy:  0.33754977746544856  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  241  Loss:  33.00203275680542  Train-Accuracy:  0.33801827125790584  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  242  Loss:  32.97822141647339  Train-Accuracy:  0.3356758022956196  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  243  Loss:  32.9980845451355  Train-Accuracy:  0.33918950573904894  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  244  Loss:  32.966403007507324  Train-Accuracy:  0.33356758022956196  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  245  Loss:  32.96031713485718  Train-Accuracy:  0.33801827125790584  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  246  Loss:  32.981910705566406  Train-Accuracy:  0.3368470367767627  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  247  Loss:  32.98303747177124  Train-Accuracy:  0.3342703209182478  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  248  Loss:  32.94837284088135  Train-Accuracy:  0.33754977746544856  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  249  Loss:  33.00450038909912  Train-Accuracy:  0.33801827125790584  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  250  Loss:  32.98442363739014  Train-Accuracy:  0.34012649332396344  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  251  Loss:  32.97306823730469  Train-Accuracy:  0.3363785429843055  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  252  Loss:  32.98773765563965  Train-Accuracy:  0.33918950573904894  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  253  Loss:  32.93788385391235  Train-Accuracy:  0.3412977278051066  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  254  Loss:  32.981093883514404  Train-Accuracy:  0.33918950573904894  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  255  Loss:  32.96106576919556  Train-Accuracy:  0.34012649332396344  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  256  Loss:  32.967562198638916  Train-Accuracy:  0.34106348090887795  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  257  Loss:  32.93867015838623  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  258  Loss:  32.96900510787964  Train-Accuracy:  0.3403607402201921  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  259  Loss:  32.964534282684326  Train-Accuracy:  0.34012649332396344  Val-Accuracy:  0.24492234169653523\n",
            "Epoch:  260  Loss:  32.93421506881714  Train-Accuracy:  0.3408292340126493  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  261  Loss:  32.94636821746826  Train-Accuracy:  0.34012649332396344  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  262  Loss:  32.944480419158936  Train-Accuracy:  0.3405949871164207  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  263  Loss:  32.94058418273926  Train-Accuracy:  0.3408292340126493  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  264  Loss:  32.985374450683594  Train-Accuracy:  0.3408292340126493  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  265  Loss:  32.97759294509888  Train-Accuracy:  0.3403607402201921  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  266  Loss:  32.96686553955078  Train-Accuracy:  0.3396579995315062  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  267  Loss:  32.92182493209839  Train-Accuracy:  0.34106348090887795  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  268  Loss:  32.97409629821777  Train-Accuracy:  0.3368470367767627  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  269  Loss:  32.990437507629395  Train-Accuracy:  0.34153197470133523  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  270  Loss:  32.94843673706055  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  271  Loss:  32.95673084259033  Train-Accuracy:  0.33989224642773486  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  272  Loss:  32.95775556564331  Train-Accuracy:  0.34293745607870696  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  273  Loss:  32.94795513153076  Train-Accuracy:  0.3396579995315062  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  274  Loss:  32.93264865875244  Train-Accuracy:  0.3408292340126493  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  275  Loss:  32.966001987457275  Train-Accuracy:  0.3403607402201921  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  276  Loss:  32.96803283691406  Train-Accuracy:  0.34153197470133523  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  277  Loss:  32.95950889587402  Train-Accuracy:  0.34246896228624973  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  278  Loss:  32.985811710357666  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  279  Loss:  32.962761878967285  Train-Accuracy:  0.34293745607870696  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  280  Loss:  32.944260120391846  Train-Accuracy:  0.3405949871164207  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  281  Loss:  32.9743275642395  Train-Accuracy:  0.3427032091824783  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  282  Loss:  32.98684644699097  Train-Accuracy:  0.34200046849379245  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  283  Loss:  32.995116233825684  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  284  Loss:  32.937865257263184  Train-Accuracy:  0.3436401967673928  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  285  Loss:  32.94522285461426  Train-Accuracy:  0.3403607402201921  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  286  Loss:  32.98051404953003  Train-Accuracy:  0.3436401967673928  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  287  Loss:  32.940539836883545  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  288  Loss:  32.94642877578735  Train-Accuracy:  0.34153197470133523  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  289  Loss:  32.972169399261475  Train-Accuracy:  0.34293745607870696  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  290  Loss:  32.92738485336304  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  291  Loss:  32.94101667404175  Train-Accuracy:  0.34293745607870696  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  292  Loss:  32.93646955490112  Train-Accuracy:  0.3441086905598501  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  293  Loss:  32.94795322418213  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  294  Loss:  32.92486238479614  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  295  Loss:  32.94648456573486  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  296  Loss:  32.95579385757446  Train-Accuracy:  0.33895525884282035  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  297  Loss:  32.92510414123535  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  298  Loss:  32.96942710876465  Train-Accuracy:  0.3405949871164207  Val-Accuracy:  0.24372759856630824\n",
            "Epoch:  299  Loss:  32.955209255218506  Train-Accuracy:  0.34106348090887795  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  300  Loss:  32.95451259613037  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  301  Loss:  32.946364402770996  Train-Accuracy:  0.34106348090887795  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  302  Loss:  32.98457145690918  Train-Accuracy:  0.34293745607870696  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  303  Loss:  32.96487283706665  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  304  Loss:  32.959476470947266  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  305  Loss:  32.924617767333984  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  306  Loss:  32.91569519042969  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  307  Loss:  32.92573356628418  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  308  Loss:  32.915690422058105  Train-Accuracy:  0.3417662215975638  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  309  Loss:  32.93424987792969  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  310  Loss:  32.94858694076538  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  311  Loss:  32.9670729637146  Train-Accuracy:  0.34293745607870696  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  312  Loss:  32.956946849823  Train-Accuracy:  0.34387444366362147  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  313  Loss:  32.908008098602295  Train-Accuracy:  0.3422347153900211  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  314  Loss:  32.975295543670654  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  315  Loss:  32.942434787750244  Train-Accuracy:  0.34387444366362147  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  316  Loss:  32.950395584106445  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  317  Loss:  32.91150665283203  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  318  Loss:  32.94306468963623  Train-Accuracy:  0.34246896228624973  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  319  Loss:  32.956056118011475  Train-Accuracy:  0.3436401967673928  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  320  Loss:  32.94906282424927  Train-Accuracy:  0.3441086905598501  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  321  Loss:  32.9619517326355  Train-Accuracy:  0.34200046849379245  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  322  Loss:  32.94794511795044  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  323  Loss:  32.93025875091553  Train-Accuracy:  0.34387444366362147  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  324  Loss:  32.93339776992798  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  325  Loss:  32.939992904663086  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  326  Loss:  32.94453763961792  Train-Accuracy:  0.3431717029749356  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  327  Loss:  32.92672109603882  Train-Accuracy:  0.34504567814476456  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  328  Loss:  32.92805337905884  Train-Accuracy:  0.3436401967673928  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  329  Loss:  32.96012210845947  Train-Accuracy:  0.3436401967673928  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  330  Loss:  32.9306321144104  Train-Accuracy:  0.3443429374560787  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  331  Loss:  32.924880027770996  Train-Accuracy:  0.3443429374560787  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  332  Loss:  32.98211097717285  Train-Accuracy:  0.34387444366362147  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  333  Loss:  32.9233775138855  Train-Accuracy:  0.3443429374560787  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  334  Loss:  32.91171073913574  Train-Accuracy:  0.34457718435230733  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  335  Loss:  32.95497179031372  Train-Accuracy:  0.34481143124853597  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  336  Loss:  32.92169189453125  Train-Accuracy:  0.34504567814476456  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  337  Loss:  32.93756580352783  Train-Accuracy:  0.34457718435230733  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  338  Loss:  32.95631647109985  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  339  Loss:  32.933964252471924  Train-Accuracy:  0.34457718435230733  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  340  Loss:  32.94639301300049  Train-Accuracy:  0.34598266572967906  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  341  Loss:  32.911510944366455  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  342  Loss:  32.95176601409912  Train-Accuracy:  0.3441086905598501  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  343  Loss:  32.94775581359863  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  344  Loss:  32.897411823272705  Train-Accuracy:  0.34481143124853597  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  345  Loss:  32.94008493423462  Train-Accuracy:  0.34481143124853597  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  346  Loss:  32.911760330200195  Train-Accuracy:  0.34551417193722184  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  347  Loss:  32.913126945495605  Train-Accuracy:  0.34387444366362147  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  348  Loss:  32.94692802429199  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  349  Loss:  32.94413614273071  Train-Accuracy:  0.34551417193722184  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  350  Loss:  32.93614196777344  Train-Accuracy:  0.3434059498711642  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  351  Loss:  32.89770221710205  Train-Accuracy:  0.34598266572967906  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  352  Loss:  32.93142366409302  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  353  Loss:  32.93007135391235  Train-Accuracy:  0.34481143124853597  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  354  Loss:  32.94247245788574  Train-Accuracy:  0.34598266572967906  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  355  Loss:  32.92644500732422  Train-Accuracy:  0.34481143124853597  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  356  Loss:  32.9201226234436  Train-Accuracy:  0.3457484188334505  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  357  Loss:  32.95161581039429  Train-Accuracy:  0.3457484188334505  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  358  Loss:  32.91875219345093  Train-Accuracy:  0.34645115952213634  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  359  Loss:  32.948002338409424  Train-Accuracy:  0.34598266572967906  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  360  Loss:  32.91623401641846  Train-Accuracy:  0.34598266572967906  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  361  Loss:  32.93782377243042  Train-Accuracy:  0.34551417193722184  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  362  Loss:  32.897929668426514  Train-Accuracy:  0.34457718435230733  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  363  Loss:  32.93160438537598  Train-Accuracy:  0.34645115952213634  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  364  Loss:  32.91598701477051  Train-Accuracy:  0.3462169126259077  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  365  Loss:  32.918139934539795  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  366  Loss:  32.930452823638916  Train-Accuracy:  0.34551417193722184  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  367  Loss:  32.92625331878662  Train-Accuracy:  0.3457484188334505  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  368  Loss:  32.93060874938965  Train-Accuracy:  0.3462169126259077  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  369  Loss:  32.89944648742676  Train-Accuracy:  0.34645115952213634  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  370  Loss:  32.940367221832275  Train-Accuracy:  0.34598266572967906  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  371  Loss:  32.94364643096924  Train-Accuracy:  0.346685406418365  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  372  Loss:  32.89634466171265  Train-Accuracy:  0.34738814710705085  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  373  Loss:  32.9357328414917  Train-Accuracy:  0.3452799250409932  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  374  Loss:  32.92690944671631  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  375  Loss:  32.92507362365723  Train-Accuracy:  0.34457718435230733  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  376  Loss:  32.88831281661987  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  377  Loss:  32.950846672058105  Train-Accuracy:  0.34645115952213634  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  378  Loss:  32.93669366836548  Train-Accuracy:  0.3462169126259077  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  379  Loss:  32.912118434906006  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  380  Loss:  32.89338254928589  Train-Accuracy:  0.34645115952213634  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  381  Loss:  32.93667030334473  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  382  Loss:  32.91557836532593  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  383  Loss:  32.94083261489868  Train-Accuracy:  0.3471539002108222  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  384  Loss:  32.907119274139404  Train-Accuracy:  0.3462169126259077  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  385  Loss:  32.897189140319824  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  386  Loss:  32.89604139328003  Train-Accuracy:  0.3457484188334505  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  387  Loss:  32.90831995010376  Train-Accuracy:  0.3471539002108222  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  388  Loss:  32.92009973526001  Train-Accuracy:  0.346685406418365  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  389  Loss:  32.91723108291626  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  390  Loss:  32.90616273880005  Train-Accuracy:  0.34738814710705085  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  391  Loss:  32.922749519348145  Train-Accuracy:  0.346685406418365  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  392  Loss:  32.890822410583496  Train-Accuracy:  0.34738814710705085  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  393  Loss:  32.8848352432251  Train-Accuracy:  0.34738814710705085  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  394  Loss:  32.92830419540405  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  395  Loss:  32.92970037460327  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  396  Loss:  32.93761873245239  Train-Accuracy:  0.34738814710705085  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  397  Loss:  32.89552307128906  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  398  Loss:  32.93466377258301  Train-Accuracy:  0.34551417193722184  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  399  Loss:  32.91150712966919  Train-Accuracy:  0.34762239400327943  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  400  Loss:  32.91485548019409  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  401  Loss:  32.889633655548096  Train-Accuracy:  0.34738814710705085  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  402  Loss:  32.91721820831299  Train-Accuracy:  0.34855938158819394  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  403  Loss:  32.93012475967407  Train-Accuracy:  0.3462169126259077  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  404  Loss:  32.900511264801025  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  405  Loss:  32.9128851890564  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  406  Loss:  32.88193130493164  Train-Accuracy:  0.3480908877957367  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  407  Loss:  32.90144872665405  Train-Accuracy:  0.34762239400327943  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  408  Loss:  32.92558288574219  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  409  Loss:  32.90042209625244  Train-Accuracy:  0.3471539002108222  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  410  Loss:  32.94078874588013  Train-Accuracy:  0.3492621222768798  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  411  Loss:  32.89589023590088  Train-Accuracy:  0.3487936284844226  Val-Accuracy:  0.24253285543608125\n",
            "Epoch:  412  Loss:  32.90997552871704  Train-Accuracy:  0.3480908877957367  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  413  Loss:  32.92543983459473  Train-Accuracy:  0.34832513469196535  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  414  Loss:  32.89877462387085  Train-Accuracy:  0.3497306160693371  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  415  Loss:  32.89425468444824  Train-Accuracy:  0.3480908877957367  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  416  Loss:  32.89330577850342  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  417  Loss:  32.90892934799194  Train-Accuracy:  0.3492621222768798  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  418  Loss:  32.89666128158569  Train-Accuracy:  0.3492621222768798  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  419  Loss:  32.88169050216675  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  420  Loss:  32.886786460876465  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  421  Loss:  32.92237091064453  Train-Accuracy:  0.34949636917310845  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  422  Loss:  32.89377689361572  Train-Accuracy:  0.34855938158819394  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  423  Loss:  32.903531551361084  Train-Accuracy:  0.34855938158819394  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  424  Loss:  32.888333320617676  Train-Accuracy:  0.34691965331459357  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  425  Loss:  32.92967367172241  Train-Accuracy:  0.3487936284844226  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  426  Loss:  32.9483699798584  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  427  Loss:  32.915454387664795  Train-Accuracy:  0.3480908877957367  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  428  Loss:  32.89612436294556  Train-Accuracy:  0.3492621222768798  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  429  Loss:  32.9161491394043  Train-Accuracy:  0.34949636917310845  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  430  Loss:  32.912421226501465  Train-Accuracy:  0.34855938158819394  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  431  Loss:  32.89130735397339  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  432  Loss:  32.9078164100647  Train-Accuracy:  0.3487936284844226  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  433  Loss:  32.91267681121826  Train-Accuracy:  0.3478566408995081  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  434  Loss:  32.88058567047119  Train-Accuracy:  0.34949636917310845  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  435  Loss:  32.86131286621094  Train-Accuracy:  0.34762239400327943  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  436  Loss:  32.90263795852661  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  437  Loss:  32.93073225021362  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  438  Loss:  32.89625787734985  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  439  Loss:  32.912739753723145  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  440  Loss:  32.89992952346802  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  441  Loss:  32.90588426589966  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  442  Loss:  32.90795135498047  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  443  Loss:  32.9036226272583  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  444  Loss:  32.89653491973877  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  445  Loss:  32.839256286621094  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.23775388291517324\n",
            "Epoch:  446  Loss:  32.88944673538208  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  447  Loss:  32.89376735687256  Train-Accuracy:  0.3492621222768798  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  448  Loss:  32.87513732910156  Train-Accuracy:  0.3487936284844226  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  449  Loss:  32.86452102661133  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  450  Loss:  32.88723659515381  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  451  Loss:  32.923792362213135  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  452  Loss:  32.88565921783447  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  453  Loss:  32.902018547058105  Train-Accuracy:  0.3490278753806512  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  454  Loss:  32.912864208221436  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  455  Loss:  32.89984178543091  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  456  Loss:  32.911213874816895  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  457  Loss:  32.90757465362549  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  458  Loss:  32.877310276031494  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  459  Loss:  32.86408805847168  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  460  Loss:  32.853697776794434  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  461  Loss:  32.90728569030762  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  462  Loss:  32.91448497772217  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  463  Loss:  32.87680149078369  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  464  Loss:  32.868993282318115  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  465  Loss:  32.885353565216064  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  466  Loss:  32.89849042892456  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  467  Loss:  32.90049076080322  Train-Accuracy:  0.3499648629655657  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  468  Loss:  32.8925347328186  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  469  Loss:  32.84837865829468  Train-Accuracy:  0.3511360974467088  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  470  Loss:  32.8754243850708  Train-Accuracy:  0.3480908877957367  Val-Accuracy:  0.24133811230585425\n",
            "Epoch:  471  Loss:  32.86569881439209  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  472  Loss:  32.89273929595947  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  473  Loss:  32.92156171798706  Train-Accuracy:  0.34949636917310845  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  474  Loss:  32.852229595184326  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  475  Loss:  32.90099287033081  Train-Accuracy:  0.34949636917310845  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  476  Loss:  32.87883234024048  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  477  Loss:  32.91662359237671  Train-Accuracy:  0.3497306160693371  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  478  Loss:  32.88757658004761  Train-Accuracy:  0.35043335675802295  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  479  Loss:  32.85852003097534  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  480  Loss:  32.864957332611084  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  481  Loss:  32.891671657562256  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  482  Loss:  32.926692485809326  Train-Accuracy:  0.3518388381353947  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  483  Loss:  32.888587951660156  Train-Accuracy:  0.35090185055048023  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  484  Loss:  32.884610652923584  Train-Accuracy:  0.3501991098617943  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  485  Loss:  32.92071056365967  Train-Accuracy:  0.3516045912391661  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  486  Loss:  32.879064083099365  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  487  Loss:  32.89622783660889  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  488  Loss:  32.85552167892456  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  489  Loss:  32.89447784423828  Train-Accuracy:  0.35090185055048023  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  490  Loss:  32.9286789894104  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  491  Loss:  32.8617057800293  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  492  Loss:  32.90353488922119  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  493  Loss:  32.92619752883911  Train-Accuracy:  0.3506676036542516  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  494  Loss:  32.88676977157593  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  495  Loss:  32.87926530838013  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  496  Loss:  32.90791130065918  Train-Accuracy:  0.35090185055048023  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  497  Loss:  32.90541648864746  Train-Accuracy:  0.35090185055048023  Val-Accuracy:  0.23894862604540024\n",
            "Epoch:  498  Loss:  32.88189172744751  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.24014336917562723\n",
            "Epoch:  499  Loss:  32.87039661407471  Train-Accuracy:  0.35137034434293746  Val-Accuracy:  0.24014336917562723\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eDupR-MTDix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}