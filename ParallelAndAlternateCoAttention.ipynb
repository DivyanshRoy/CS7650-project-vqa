{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QESkgWzv_idX",
        "colab_type": "code",
        "outputId": "9d69a995-e75d-42e3-ebcd-8a224beb2aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip vgg_feature_map_modified.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  vgg_feature_map_modified.zip\n",
            "  inflating: content/vgg_feature_map/vgg_train_image_features_number.npy  \n",
            "  inflating: content/vgg_feature_map/vgg_train_image_features_other.npy  \n",
            "  inflating: content/vgg_feature_map/vgg_train_image_features_yesno.npy  \n",
            "  inflating: content/vgg_feature_map/vgg_val_image_features_number.npy  \n",
            "  inflating: content/vgg_feature_map/vgg_val_image_features_other.npy  \n",
            "  inflating: content/vgg_feature_map/vgg_val_image_features_yesno.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvVh0p3QBSVQ",
        "colab_type": "code",
        "outputId": "939b8ddd-88ab-461e-b370-4203b6c1d3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!unzip revised_data_new.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  revised_data_new.zip\n",
            "  inflating: revised_data/train_answers_number.npy  \n",
            "  inflating: revised_data/train_answers_other.npy  \n",
            "  inflating: revised_data/train_answers_yesno.npy  \n",
            "  inflating: revised_data/train_image_features_number.npy  \n",
            "  inflating: revised_data/train_image_features_other.npy  \n",
            "  inflating: revised_data/train_image_features_yesno.npy  \n",
            "  inflating: revised_data/train_questions_number.npy  \n",
            "  inflating: revised_data/train_questions_other.npy  \n",
            "  inflating: revised_data/train_questions_yesno.npy  \n",
            "  inflating: revised_data/val_answers_number.npy  \n",
            "  inflating: revised_data/val_answers_other.npy  \n",
            "  inflating: revised_data/val_answers_yesno.npy  \n",
            "  inflating: revised_data/val_image_features_number.npy  \n",
            "  inflating: revised_data/val_image_features_other.npy  \n",
            "  inflating: revised_data/val_image_features_yesno.npy  \n",
            "  inflating: revised_data/val_questions_number.npy  \n",
            "  inflating: revised_data/val_questions_other.npy  \n",
            "  inflating: revised_data/val_questions_yesno.npy  \n",
            "  inflating: revised_data/weights_matrix.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqcAlPPUBEG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8KNqcvKArRf",
        "colab_type": "code",
        "outputId": "5c247b48-e729-4151-b507-4cbe81810053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_image = np.load(\"content/vgg_feature_map/vgg_train_image_features_other.npy\")\n",
        "print(train_image.shape)\n",
        "\n",
        "val_image = np.load(\"content/vgg_feature_map/vgg_val_image_features_other.npy\")\n",
        "print(val_image.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3932, 512, 196)\n",
            "(681, 512, 196)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjYB8vXoCeU6",
        "colab_type": "code",
        "outputId": "5884a02f-5a3c-4c25-f07d-5f2e3a5ab541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_question = np.load(\"revised_data/train_questions_other.npy\")\n",
        "train_answer = np.load(\"revised_data/train_answers_other.npy\")\n",
        "print(train_question.shape)\n",
        "print(train_answer.shape)\n",
        "\n",
        "val_question = np.load(\"revised_data/val_questions_other.npy\")\n",
        "val_answer = np.load(\"revised_data/val_answers_other.npy\")\n",
        "print(val_question.shape)\n",
        "print(val_answer.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3932, 25)\n",
            "(3932, 1)\n",
            "(681, 25)\n",
            "(681, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmB59HWDBb-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ParallelCoAttention(nn.Module):\n",
        "  def __init__(self, d, t, k, vocab_size, dropout):\n",
        "    super(ParallelCoAttention, self).__init__()\n",
        "    self.d = d \n",
        "    self.embedding_dim = d\n",
        "    self.t = t\n",
        "    self.k = k\n",
        "    self.vocab_size = vocab_size\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "    self.W_b = nn.Linear(self.d, self.d)\n",
        "    self.W_q = nn.Linear(self.d, self.k)\n",
        "    self.W_v = nn.Linear(self.d, self.k)\n",
        "    self.w_hv = nn.Linear(self.k, 1)\n",
        "    self.w_hq = nn.Linear(self.k, 1)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.Softmax(dim =1)\n",
        "\n",
        "\n",
        "  def forward(self, questions, images):\n",
        "    questions = self.embedding(questions)\n",
        "    x = self.dropout(self.W_b(questions)) \n",
        "    C = self.tanh(torch.bmm(x,images)) \n",
        "\n",
        "    H_v = self.dropout(self.tanh(self.W_v(torch.transpose(images, 1, 2)) + torch.bmm(torch.transpose(C,1,2),self.W_q(questions)))) \n",
        "    a_v = self.dropout(self.softmax(self.w_hv(H_v)))\n",
        "    a_v = torch.transpose(a_v, 1,2) \n",
        "    v_hat = torch.sum(a_v * images, axis= 2) \n",
        "\n",
        "    H_q = self.dropout(self.tanh(self.W_q(questions) + torch.bmm(C,self.W_v(torch.transpose(images, 1, 2))))) \n",
        "    a_q = self.dropout(self.softmax(self.w_hq(H_q)))\n",
        "    q_hat = torch.sum(a_q*questions, axis =1) \n",
        "    return (q_hat, v_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4zQmNUK5XEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlternateCoAttention(nn.Module):\n",
        "  def __init__(self, d, k, vocab_size, dropout):\n",
        "    super(AlternateCoAttention, self).__init__()\n",
        "    self.d = d\n",
        "    self.k = k\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.d)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.W_x_1 = nn.Linear(self.d, self.k)\n",
        "    self.W_g_1 = nn.Linear(self.d, self.k)\n",
        "    self.W_hx_1 = nn.Linear(self.k, 1)\n",
        "\n",
        "    self.W_x_2 = nn.Linear(self.d, self.k)\n",
        "    self.W_g_2 = nn.Linear(self.d, self.k)\n",
        "    self.W_hx_2 = nn.Linear(self.k, 1)\n",
        "\n",
        "    self.W_x_3 = nn.Linear(self.d, self.k)\n",
        "    self.W_g_3 = nn.Linear(self.d, self.k)\n",
        "    self.W_hx_3 = nn.Linear(self.k, 1)\n",
        "\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, questions, images):\n",
        "    questions = self.embedding(questions)\n",
        "    H_1 = self.dropout(self.tanh(self.W_x_1(questions)))\n",
        "    a_x_1 = self.dropout(self.softmax(self.W_hx_1(H_1))) \n",
        "    x_hat_1 = torch.sum(a_x_1 * questions, axis=1) \n",
        "\n",
        "    H_2 = self.dropout(self.tanh(self.W_x_2(torch.transpose(images,1,2)) + self.W_g_2(x_hat_1).unsqueeze(1)))\n",
        "    a_x_2 = self.dropout(self.softmax(self.W_hx_2(H_2)))\n",
        "    x_hat_2 = torch.sum(a_x_2*torch.transpose(images,1,2), axis=1)\n",
        "\n",
        "    H_3 = self.dropout(self.tanh(self.W_x_3(questions) + self.W_g_3(x_hat_2).unsqueeze(1)))\n",
        "    a_x_3 = self.dropout(self.softmax(self.W_hx_3(H_3)))\n",
        "    x_hat_3 = torch.sum(a_x_3*questions, axis=1)\n",
        "    return (x_hat_2, x_hat_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq8kZbL-EQmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AnswerGeneration(nn.Module):\n",
        "  def __init__(self, d, d_prime, dropout):\n",
        "    super(AnswerGeneration, self).__init__()\n",
        "    self.d = d\n",
        "    self.d_prime = d_prime\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.Softmax(dim = 1)\n",
        "    self.W = nn.Linear(self.d, self.d_prime)\n",
        "    self.W_h = nn.Linear(self.d_prime, 1000) #no of classes for yesno -2, number - 100, other - 1000 --verify again \n",
        "\n",
        "  def forward(self, q_hat, v_hat):\n",
        "    h = self.dropout(self.tanh(self.W(q_hat + v_hat)))\n",
        "    return self.softmax(self.dropout(self.W_h(h)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqRrqt2DUWtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MainModel(nn.Module):\n",
        "  def __init__(self, d, t, k, d_prime, vocab_size, dropout):\n",
        "    super(MainModel, self).__init__()\n",
        "    self.d = d\n",
        "    self.t = t\n",
        "    self.k = k \n",
        "    self.d_prime = d_prime\n",
        "    self.vocab_size = vocab_size\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.parallel = ParallelCoAttention(self.d, self.t, self.k, self.vocab_size, self.dropout)\n",
        "    self.alternate = AlternateCoAttention(self.d, self.k, self.vocab_size, self.dropout)\n",
        "    self.answer = AnswerGeneration(self.d, self.d_prime, self.dropout)\n",
        "\n",
        "  def forward(self, questions, images):\n",
        "    q_hat_p, v_hat_p = self.parallel(questions, images)\n",
        "    v_hat_a, q_hat_a = self.alternate(questions, images)\n",
        "    answer_p = self.answer(q_hat_p, v_hat_p)\n",
        "    answer_a = self.answer(q_hat_a, v_hat_a)\n",
        "    return (answer_p, answer_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMbTJp3GW1lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = 512\n",
        "t = 25\n",
        "k = 512\n",
        "d_prime = 128 \n",
        "vocab_size = 400001\n",
        "dropout = 0\n",
        "model = MainModel(d, t, k, d_prime, vocab_size, dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpyFVqUlaocb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_x = torch.Tensor(train_question).type(torch.long)\n",
        "tensor_y = torch.Tensor(train_image).type(torch.float)\n",
        "tensor_z = torch.Tensor(train_answer).type(torch.long).squeeze()\n",
        "\n",
        "trainset = data.TensorDataset(tensor_x, tensor_y, tensor_z)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=300, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENdcjRtwbbMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_x = torch.Tensor(val_question).type(torch.long)\n",
        "tensor_y = torch.Tensor(val_image).type(torch.float)\n",
        "tensor_z = torch.Tensor(val_answer).type(torch.long).squeeze()\n",
        "\n",
        "valset = data.TensorDataset(tensor_x, tensor_y, tensor_z)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size = 300, shuffle = True, num_workers = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKiR8k-2chFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-2, weight_decay=1e-8, momentum=0.99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHQCWSSvel6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(predictions, labels):\n",
        "  predictions = torch.max(predictions, axis=1)[1]\n",
        "  ab = torch.abs(predictions-labels)\n",
        "  ab = ab.detach().numpy()\n",
        "  mn = np.minimum(ab, 1)\n",
        "  eq = 1-mn\n",
        "  correct = np.sum(eq)\n",
        "  total = eq.shape[0]\n",
        "  return correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExhwqL6dheb",
        "colab_type": "code",
        "outputId": "859189e6-6fa7-4f29-b31c-ef4e2a3d6ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(256):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        questions, images, labels = data\n",
        "      \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs_p, outputs_a = model(questions, images)\n",
        "        batch_correct, batch_total = get_accuracy(outputs_p, labels)\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "        loss = criterion(outputs_p, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        total_loss += running_loss\n",
        "        running_loss = 0.0\n",
        "\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(valloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          questions, images, labels = data\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs_p, outputs_a = model(questions, images)\n",
        "          batch_correct, batch_total = get_accuracy(outputs_p, labels)\n",
        "          val_correct += batch_correct\n",
        "          val_total += batch_total\n",
        "          \n",
        "    print(\"Epoch: \",epoch,\" Loss: \",total_loss,\" Train-Accuracy: \", correct/total,\" Val-Accuracy: \",val_correct/val_total)\n",
        "    \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  Loss:  96.70860767364502  Train-Accuracy:  0.000254323499491353  Val-Accuracy:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag0tql7hSRYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}